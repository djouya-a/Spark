{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### covert forext data and save it to csv by pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('EURUSD1.csv', header = None, sep=\"\\t\")\n",
    "df.columns = ['time','open','high','low','close','volume']\n",
    "df = df.drop('time', axis=1)\n",
    "df.to_csv(\"forex.csv\",sep=\",\",index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data by spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sparksession object\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('lin_reg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Linear Regression from spark's MLlib\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "df=spark.read.csv('forex.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#explore the data\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|summary|open               |high                |low                 |close               |volume            |\n",
      "+-------+-------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|count  |50000              |50000               |50000               |50000               |50000             |\n",
      "|mean   |1.1621056084000059 |1.1621945742000055  |1.1620166916        |1.1621050774        |271.81078         |\n",
      "|stddev |0.02222208413534274|0.022230970074184387|0.022212394925094324|0.022221542503365454|1352.8702800252788|\n",
      "|min    |1.12198            |1.12222             |1.12192             |1.12199             |1                 |\n",
      "|max    |1.19632            |1.19656             |1.19624             |1.19633             |122732            |\n",
      "+-------+-------------------+--------------------+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view statistical measures of data \n",
    "df.describe().show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vectorassembler to create dense vectors\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open', 'high', 'low', 'close', 'volume']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the vector assembler \n",
    "vec_assmebler=VectorAssembler(inputCols=['open', 'high', 'low', 'close', 'volume'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- volume: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#transform the values\n",
    "features_df=vec_assmebler.transform(df)\n",
    "#validate the presence of dense vectors \n",
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|features                                                    |\n",
      "+------------------------------------------------------------+\n",
      "|[1.12456,1.1246399999999999,1.1245399999999999,1.1246,101.0]|\n",
      "|[1.12461,1.12461,1.1245100000000001,1.12459,68.0]           |\n",
      "|[1.12458,1.1246,1.12445,1.12447,72.0]                       |\n",
      "|[1.12447,1.12448,1.12436,1.12438,71.0]                      |\n",
      "|[1.12437,1.12439,1.12436,1.12438,24.0]                      |\n",
      "+------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the details of dense vector\n",
    "features_df.select('features').show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------+\n",
      "|features                                                    |volume|\n",
      "+------------------------------------------------------------+------+\n",
      "|[1.12456,1.1246399999999999,1.1245399999999999,1.1246,101.0]|101   |\n",
      "|[1.12461,1.12461,1.1245100000000001,1.12459,68.0]           |68    |\n",
      "|[1.12458,1.1246,1.12445,1.12447,72.0]                       |72    |\n",
      "|[1.12447,1.12448,1.12436,1.12438,71.0]                      |71    |\n",
      "|[1.12437,1.12439,1.12436,1.12438,24.0]                      |24    |\n",
      "+------------------------------------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create data containing input features and output column\n",
    "model_df=features_df.select('features','volume')\n",
    "model_df.show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data - Train & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34844, 2)\n",
      "(15156, 2)\n"
     ]
    }
   ],
   "source": [
    "#split the data into 70/30 ratio for train test purpose\n",
    "train_df,test_df=model_df.randomSplit([0.7,0.3])\n",
    "print((train_df.count(), len(train_df.columns)))\n",
    "print((test_df.count(), len(test_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            volume|\n",
      "+-------+------------------+\n",
      "|  count|             34844|\n",
      "|   mean|269.44564343932956|\n",
      "| stddev|1275.0272174087052|\n",
      "|    min|                 1|\n",
      "|    max|            102123|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.966648742397079e-10"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build Linear Regression model \n",
    "lin_Reg=LinearRegression(labelCol='volume')\n",
    "#fit the linear regression model on training data set \n",
    "lr_model=lin_Reg.fit(train_df)\n",
    "lr_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.130356841987603e-10,-3.0030382118057333e-09,2.4681944514026168e-09,2.9140645566448707e-10,0.9999999999999999]\n"
     ]
    }
   ],
   "source": [
    "print(lr_model.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions=lr_model.evaluate(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3928561812065817e-23\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(training_predictions.meanSquaredError)\n",
    "print(training_predictions.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions on test data \n",
    "test_results=lr_model.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|6.764366844436154...|\n",
      "|7.105427357601002...|\n",
      "|6.52278231427772E-12|\n",
      "|6.437517185986508...|\n",
      "|6.73594513500575E-12|\n",
      "|6.764366844436154...|\n",
      "|6.52278231427772E-12|\n",
      "|6.764366844436154...|\n",
      "|6.73594513500575E-12|\n",
      "|6.693312570860144...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the residual errors based on predictions \n",
    "test_results.residuals.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "3.73197938133693e-12\n",
      "1.3927670102723974e-23\n"
     ]
    }
   ],
   "source": [
    "#coefficient of determination value for model\n",
    "print(test_results.r2)\n",
    "print(test_results.rootMeanSquaredError)\n",
    "print(test_results.meanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
