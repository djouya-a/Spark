{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sparksession object\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('log_reg').getOrCreate()\n",
    "\n",
    "#Load the dataset\n",
    "df=spark.read.csv('covid.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+-----+----+-----+------+-----------------------+-----+--------------------+-----------+------------+----------------------------------------------------------+\n",
      "|   dateRep|day|month|year|cases|deaths|countriesAndTerritories|geoId|countryterritoryCode|popData2019|continentExp|Cumulative_number_for_14_days_of_COVID-19_cases_per_100000|\n",
      "+----------+---+-----+----+-----+------+-----------------------+-----+--------------------+-----------+------------+----------------------------------------------------------+\n",
      "|2020-08-22| 22|    8|2020|   38|     0|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.31061883|\n",
      "|2020-08-21| 21|    8|2020|   97|     2|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.41576644|\n",
      "|2020-08-20| 20|    8|2020|  160|     8|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.26855978|\n",
      "|2020-08-19| 19|    8|2020|    0|     0|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.02409158|\n",
      "|2020-08-18| 18|    8|2020|    3|     0|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.23964419|\n",
      "|2020-08-17| 17|    8|2020|   45|     5|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.32901966|\n",
      "|2020-08-16| 16|    8|2020|  120|     7|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.21072859|\n",
      "|2020-08-15| 15|    8|2020|    7|     0|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                1.89528575|\n",
      "|2020-08-14| 14|    8|2020|   79|     9|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                 2.3185049|\n",
      "|2020-08-13| 13|    8|2020|   76|    10|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.29747538|\n",
      "|2020-08-12| 12|    8|2020|  215|    32|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.09769491|\n",
      "|2020-08-11| 11|    8|2020|    0|     0|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                1.80328159|\n",
      "|2020-08-10| 10|    8|2020|    0|     0|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.07929408|\n",
      "|2020-08-09|  9|    8|2020|   39|     5|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.35793526|\n",
      "|2020-08-08|  8|    8|2020|   78|     9|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.57348786|\n",
      "|2020-08-07|  7|    8|2020|   41|     0|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.65234858|\n",
      "|2020-08-06|  6|    8|2020|   67|     4|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.57874525|\n",
      "|2020-08-05|  5|    8|2020|   82|     6|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.89681678|\n",
      "|2020-08-04|  4|    8|2020|   37|     4|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                2.97567749|\n",
      "|2020-08-03|  3|    8|2020|    0|     1|            Afghanistan|   AF|                 AFG|3.8041757E7|        Asia|                                                 3.2464326|\n",
      "+----------+---+-----+----+-----+------+-----------------------+-----+--------------------+-----------+------------+----------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer()\\\n",
    "  .setInputCol(\"dateRep\")\\\n",
    "  .setOutputCol(\"day_of_week_index\").fit(df)\n",
    "\n",
    "df2 = indexer.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-------------------+\n",
      "|   dateRep|day_of_week_index|day_of_week_encoded|\n",
      "+----------+-----------------+-------------------+\n",
      "|2020-08-22|            112.0|  (235,[112],[1.0])|\n",
      "|2020-08-21|             96.0|   (235,[96],[1.0])|\n",
      "|2020-08-20|             95.0|   (235,[95],[1.0])|\n",
      "|2020-08-19|             94.0|   (235,[94],[1.0])|\n",
      "|2020-08-18|             93.0|   (235,[93],[1.0])|\n",
      "|2020-08-17|            111.0|  (235,[111],[1.0])|\n",
      "|2020-08-16|             92.0|   (235,[92],[1.0])|\n",
      "|2020-08-15|             91.0|   (235,[91],[1.0])|\n",
      "|2020-08-14|             90.0|   (235,[90],[1.0])|\n",
      "|2020-08-13|             89.0|   (235,[89],[1.0])|\n",
      "|2020-08-12|             88.0|   (235,[88],[1.0])|\n",
      "|2020-08-11|             87.0|   (235,[87],[1.0])|\n",
      "|2020-08-10|             86.0|   (235,[86],[1.0])|\n",
      "|2020-08-09|             85.0|   (235,[85],[1.0])|\n",
      "|2020-08-08|             84.0|   (235,[84],[1.0])|\n",
      "|2020-08-07|             83.0|   (235,[83],[1.0])|\n",
      "|2020-08-06|             82.0|   (235,[82],[1.0])|\n",
      "|2020-08-05|             81.0|   (235,[81],[1.0])|\n",
      "|2020-08-04|             80.0|   (235,[80],[1.0])|\n",
      "|2020-08-03|             79.0|   (235,[79],[1.0])|\n",
      "+----------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "encoder = OneHotEncoder()\\\n",
    "  .setInputCol(\"day_of_week_index\")\\\n",
    "  .setOutputCol(\"day_of_week_encoded\")\n",
    "\n",
    "df3 = encoder.fit(df2)\n",
    "df3=df3.transform(df2)\n",
    "df4=df3.select('dateRep','day_of_week_index','day_of_week_encoded')\n",
    "df4.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+------+\n",
      "|geoId|month|cases|deaths|\n",
      "+-----+-----+-----+------+\n",
      "|   ES|    8| 8148|    25|\n",
      "|   ES|    8|    0|     0|\n",
      "|   ES|    8| 7039|    16|\n",
      "|   ES|    8| 6671|   127|\n",
      "|   ES|    8| 5114|    24|\n",
      "+-----+-----+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "df=df.where(f.col(\"geoId\").isin({\"FR\", \"IT\", \"ES\"})).select('geoId','month','cases','deaths')\n",
    "df=df.orderBy(\"geoId\", ascending=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+\n",
      "|geoId|month|deaths_total|\n",
      "+-----+-----+------------+\n",
      "|   ES|    1|           0|\n",
      "|   FR|    1|           0|\n",
      "|   IT|    1|           0|\n",
      "|   FR|    2|           2|\n",
      "|   ES|    2|           0|\n",
      "+-----+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df.groupBy([\"geoId\",\"month\"]).sum(\"deaths\").withColumnRenamed(\"sum(deaths)\", \"deaths_total\")\\\n",
    "    .sort((\"month\")).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
